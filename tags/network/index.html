<!DOCTYPE html>
<html lang="en">
<head>
  
    <title>network :: GiddyPoet</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="" />
<meta name="keywords" content="" />

  <meta name="robots" content="noodp" />

<link rel="canonical" href="https://giddypoet.github.io/tags/network/" />






  
  
  
  
  
  <link rel="stylesheet" href="https://giddypoet.github.io/styles.css">







  <link rel="shortcut icon" href="https://giddypoet.github.io/img/theme-colors/blue.png">
  <link rel="apple-touch-icon" href="https://giddypoet.github.io/img/theme-colors/blue.png">



<meta name="twitter:card" content="summary" />

  
    <meta name="twitter:site" content="" />
  
    <meta name="twitter:creator" content="" />



<meta property="og:locale" content="en" />
<meta property="og:type" content="website" />
<meta property="og:title" content="network">
<meta property="og:description" content="" />
<meta property="og:url" content="https://giddypoet.github.io/tags/network/" />
<meta property="og:site_name" content="GiddyPoet" />

  
    <meta property="og:image" content="https://giddypoet.github.io/img/favicon/blue.png">
  

<meta property="og:image:width" content="1200">
<meta property="og:image:height" content="627">





  <link href="/tags/network/index.xml" rel="alternate" type="application/rss+xml" title="GiddyPoet" />









</head>
<body class="blue">


<div class="container headings--one-size">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="/">
  <div class="logo">
    Terminal
  </div>
</a>

    </div>
    
      <ul class="menu menu--mobile">
  <li class="menu__trigger">Menu&nbsp;▾</li>
  <li>
    <ul class="menu__dropdown">
      
        
          <li><a href="/about">About</a></li>
        
      
        
          <li><a href="/showcase">Showcase</a></li>
        
      
      
    </ul>
  </li>
</ul>

    
    
  </div>
  
    <nav class="navigation-menu">
  <ul class="navigation-menu__inner menu--desktop">
    
      
        
          <li><a href="/about">About</a></li>
        
      
        
          <li><a href="/showcase">Showcase</a></li>
        
      
      
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
  
  <div class="posts">
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="https://giddypoet.github.io/posts/wireguard/">wireguard</a>
        </h1>
        <div class="post-meta">
          
            <time class="post-date">
              2022-07-19 ::
            </time>
          
          
        </div>

        
          <span class="post-tags">
            
            #<a href="https://giddypoet.github.io/tags/network/">network</a>&nbsp;
            
          </span>
        

        


        <div class="post-content">
          
            WireGuard WireGuard是由Jason Donenfeld等大佬用C语言编写的一个开源VPN协议，被视为下一代VPN，旨在解决现有VPN技术如IPSec、Openvpn等技术的痛点。 WireGuard是一个利用现有社会最先进的加密技术而产生的非常简单和快捷的VPN工具。它的目标是比 IPsec更快，更简单，更精简，更易用，同时避免大规模配置IPsec的麻烦事。同时WireGuard也打算比OpenVPN更高效。
配置使用 WireGuard相关定义 Peer：节点，对于WireGuard来说所有节点之间都是对等的，每一个启动WireGuard实例的节点都是一个peer Bounce Server(中继服务器)：类似内网穿透的原理，当设备在NAT内，需要进行通信，则可以通过中继服务器实现两个节点之间的通信，中继服务作为一个Peer，充当消息的中介。 私钥：WireGuard所用的私钥，通过wg genkey生成 公钥：WireGuard所用的公钥，通过wg genkey privatekey生成公钥，公钥在与邻居节点建立连接关系的时候使用 IP漫游：WireGuard由于是无连接的，因此如果双方地址发生变动，通过协议可以记录其新地址 WireGuard工作模式 Direct Node-to-Node：点对点模式，节点在同一局域网或者都在公网 Node behind local NAT to Public node：一个在内网通过NAT访问公网节点，配置PerisistentKeepalived，实现连接保持，维护NAT设备上的连接信息 Node behind local NAT to node behind remote NAT (via relay)：两个节点都在NAT内，通过中继服务器实现内网穿透，中继服务器用于转发连接 Node behind local NAT to node behind remote NAT (via UDP NAT hole-punching)：UDP nat打洞模式，udp打洞 WireGuard配置 本测试场景基于vmware虚拟机测试，虚拟出两台设备，IP分别为192.168.74.150和192.168.74.151。采用的是Ubuntu22.04。
本地节点配置
&lt;!-- node1 --&gt; [Interface] Address = 172.16.1.11/24 ListenPort = 8001 PrivateKey = 6JNM0s6crFOAleXhL+rt6kJTyyFrXWrVql97ZnvTmUQ= [Peer] PublicKey = 94jlm8+3rr5KtFMJqHubgDgRa87/Fb0Xc9ql2LUp2RA= AllowedIPs = 0.
          
        </div>

        
          <div>
            <a class="read-more button" href="/posts/wireguard/">Read more →</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="https://giddypoet.github.io/posts/raw-socket/">raw_socket</a>
        </h1>
        <div class="post-meta">
          
            <time class="post-date">
              2022-07-08 ::
            </time>
          
          
        </div>

        
          <span class="post-tags">
            
            #<a href="https://giddypoet.github.io/tags/network/">network</a>&nbsp;
            
          </span>
        

        


        <div class="post-content">
          
            RAW_SOCKET 我们常用的套接字类型主要就是：
TCP UDP 原始套接字区别于上述的套接字，提供了普通TCP和UDP套接字不具备的3个能力： 读写ICMPv4、IGMPv4和IGMPv6等分组 有了原始套接字，进程可以读取内核不处理的IP type类型 有了原始套接字，进程可以使用IP_HDRINCL套接字选项构造TCP或UDP分组 原始套接字创建 原始套接字协议类型：
// netinet/in.h enum { IPPROTO_IP = 0,	/* Dummy protocol for TCP. */ #define IPPROTO_IP	IPPROTO_IP IPPROTO_ICMP = 1,	/* Internet Control Message Protocol. */ #define IPPROTO_ICMP	IPPROTO_ICMP IPPROTO_IGMP = 2,	/* Internet Group Management Protocol. */ #define IPPROTO_IGMP	IPPROTO_IGMP IPPROTO_IPIP = 4,	/* IPIP tunnels (older KA9Q tunnels use 94). */ #define IPPROTO_IPIP	IPPROTO_IPIP IPPROTO_TCP = 6,	/* Transmission Control Protocol.
          
        </div>

        
          <div>
            <a class="read-more button" href="/posts/raw-socket/">Read more →</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="https://giddypoet.github.io/posts/ip-range/">ip_range</a>
        </h1>
        <div class="post-meta">
          
            <time class="post-date">
              2022-06-13 ::
            </time>
          
          
        </div>

        
          <span class="post-tags">
            
            #<a href="https://giddypoet.github.io/tags/network/">network</a>&nbsp;
            
          </span>
        

        


        <div class="post-content">
          
            ip地址范围判断问题 在实现场景中，时长遇到需要判断ip地址是否在范围内，或者ip地址是否在这个网段内，因此将简述ip地址判断问题，目前支持以下场景。
ip1-ip2 ip/CIDR (ip/24) ip/netmask (ip/255.255.255.0) ip地址判断 ip地址格式 常用的地址格式类型：
struct sockaddr { unsigned short sa_family; // address family, AF_xxx char sa_data[14]; // 14 bytes of protocol address }; struct sockaddr_in { short sin_family; // e.g. AF_INET, AF_INET6 unsigned short sin_port; // e.g. htons(3490) struct in_addr sin_addr; // see struct in_addr, below char sin_zero[8]; // zero this if you want to }; struct sockaddr_in6 { u_int16_t sin6_family; // address family, AF_INET6 u_int16_t sin6_port; // port number, Network Byte Order u_int32_t sin6_flowinfo; // IPv6 flow information struct in6_addr sin6_addr; // IPv6 address u_int32_t sin6_scope_id; // Scope ID }; struct sockaddr_storage { sa_family_t ss_family; // address family // all this is padding, implementation specific, ignore it: char __ss_pad1[_SS_PAD1SIZE]; int64_t __ss_align; char __ss_pad2[_SS_PAD2SIZE]; }; struct sockaddr 通常不会自己创建，该结构体，一般都是通过struct sockaddr_in和struct sockaddr_in6进行转换，由于历史因素，因此套接字api都只支持struct sockaddr，通过family字段进行判断，同时支持ipv4和ipv6，如果一个ip地址是ipv4,它只会读取其前4个字节，如果是ipv6，则会读取完整的16个字节.
          
        </div>

        
          <div>
            <a class="read-more button" href="/posts/ip-range/">Read more →</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="https://giddypoet.github.io/posts/dpdk%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA/">dpdk深入浅出</a>
        </h1>
        <div class="post-meta">
          
            <time class="post-date">
              2022-04-10 ::
            </time>
          
          
        </div>

        
          <span class="post-tags">
            
            #<a href="https://giddypoet.github.io/tags/network/">network</a>&nbsp;
            
          </span>
        

        


        <div class="post-content">
          
            第一章 认识DPDK 主流包处理硬件平台 简单介绍了当前从互联网面临的挑战：从计算密集型设备转换为IO密集型设备，同时介绍了当前主流包处理的硬件平台，并对其在不同领域的优缺点做了阐述：
硬件加速器：适用于功能固化，功能具有高性能低成本的特点 网络处理器：提供了包处理逻辑软件可编程的能力，在获得灵活性的同事兼顾了高性能的硬件包处理 多核处理器：更为复杂多变的高层包处理上拥有优势 硬件加速器 ASIC和FPGA。
涉及集成电路和嵌入式设备，这里不再赘述。
网络处理器 网络处理器(Network Processer Unit，NPU)是专门为处理数据包而设计的可编程通用处理器，采用多内核并行处理结构，其常被应用于通信领域的各种任务，比如包处理、协议分析、路由查找、声音/数据 的汇聚、防火墙、QoS等。
多核处理器 由当前CPU性能的扩展方式引入了SOC，同时简单介绍了当前主流厂商的多核处理器的SOC平台。
初识DPDK IA(intel architecture)不适合进行数据包处理吗 传统linux包处理流程:
数据包到达网卡 网卡设备依据配置进行DMA操作，简单来说就是将网卡中的数据直接拷贝到内存中，避免cpu浪费大量的时间片用于数据拷贝。（其实总线上有一个总的DMA控制器用于做DMA操作，不仅网卡，同时硬盘等其他IO设备都要使用DMA控制器） 网卡发送中断，通知CPU。（此处还涉及多队列网卡，网卡不同的队列中断号不一样） 驱动软件填充读写缓冲区数据结构。 数据报文到达内核协议栈，进行高层处理。 如果最终应用在用户态，数据将从内核拷贝至用户态。（涉及零拷贝知识，mmap，sendfile等） 如果最终应用在内核态，在内核继续进行。 影响收包性能的主要因素：
cpu中断，频繁的上下文切换，导致性能低下 数据拷贝，从网卡拷贝到内核，从内核拷贝到用户态 操作系统调度线程切换，导致cache替换，线程在不同核之间频繁切换，核减线程导致cache miss和cache write back造成大量的性能损失。 内存页表查询，大量的IO操作会剧烈的增加内存的查找，导致性能下降。 上述流程会引发一个问题，即便通过DMA的形式，在IO密集型的设备上，依然会因为触发大量的中断引起大量的开销，导致系统无法承受，因此引入了NAPI机制，其策略是设定中断阈值，当网卡上的中断未超过阈值，则采用中断模式，如果中断超过阈值，则系统被中断唤醒后，尽量使用轮询的方式一次性处理多个数据包，直到网络再次空闲重新传入中断等待。
其实，在上述过程中，发现除了网卡频繁触发中断，影响包处理性能，同时在内核态和用户态之间频繁发生数据拷贝也会大大的影响包处理性能。
netmap内存映射网卡的packet buffer到用户态，实现了自己的收发报文的circular ring来对应网卡的ring。越过内核态。
cpu亲和性，通过CPU亲和性，将线程绑定到cpu单个核上执行，cache miss和cache write back问题。
DPDK通过以下技术解决了上述问题：
轮询替换中断，避免中断上下文切换的开销 用户态驱动，在这种工作方式中，规避了不必要的内存拷贝，又避免了系统调用。 亲和性与独占，dpdk工作在用户态，利用线程的CPU亲和绑定的方式，特定任务值在某个核上工作。好处是可避免线程在不同核间频繁切换，核间线程切换容易导致因cache miss和cache write back造成的大量性能损失。 降低内存开销，通过大页内存降低TLB miss，利用内存多通道的交错访问能够有效提高内存访问的有效带宽。 DPDK框架简介 核心库Core Libs：提供系统抽象、大页内存、缓存池、定时器及无锁环等基础组件 PMD库：提供全用户态的驱动，以便通过轮询和线程绑定得到极高的网络吞吐，支持各种本地和虚拟网卡 Classify库：支持精确匹配(Exact Match)、最长匹配(LPM)和通配符匹配(ACL)，提供常用的包处理的查表操作 Qos库：提供网络服务质量相关组件，如限速(Meter)和调度(Sched) 上述是DPDK主要的库，其实还提供了一些对于运行频率调整(Power)，与Linux Kernel Stack建立快速通道的(KNI Kernel Network Interface)。而Packet FrameWrok和DISTRIB是为了搭建更为复杂的多核流水线处理模型提供了基础组件。
解读数据包处理能力 实际上以太网帧数据最小是64个字节，其中包括46个字节的数据部分，2个字节的协议类型，12个字节的目的mac地址和源mac地址，以及4个字节的校验和。每个以太网帧默认帧间距为12个字节，同时每个帧还有7个字节的前导，和一个自己的帧首定界，因此一个最小以太网帧为46+2+12+4+12+7+1=84个字节，672个bit。
          
        </div>

        
          <div>
            <a class="read-more button" href="/posts/dpdk%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA/">Read more →</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="https://giddypoet.github.io/posts/mtu/">mtu</a>
        </h1>
        <div class="post-meta">
          
            <time class="post-date">
              2022-03-25 ::
            </time>
          
          
        </div>

        
          <span class="post-tags">
            
            #<a href="https://giddypoet.github.io/tags/network/">network</a>&nbsp;
            
          </span>
        

        


        <div class="post-content">
          
            MTU Maximum Transmission Unit 最大传输单元。
不同链路介质对网络有不同的默认MTU值，以下是一些常见的默认值:
以太网MTU通常被设置为1500。
为什么以太网帧mtu被设为1500 早期的以太网使用共享链路的工作方式，为了保证CSMA/CD（载波多路复用/冲突检测）机制，所以规定了以太帧长度最小为64字节，最大为1518字节。最小64字节是为了保证最极端的冲突能被检测到，64字节是能被检测到的最小值；最大不超过1518字节是为了防止过长的帧传输时间过长而占用共享链路太长时间导致其他业务阻塞。所以规定以太网帧大小为64~1518字节，虽然技术不断发展，但协议一直没有更改。
以太网最大的数据帧是1518字节，这样刨去帧头14字节和帧尾CRC校验部分4字节，那么剩下承载上层IP报文的地方最大就只有1500字节，这个值就是以太网的默认MTU值。这个MTU就是网络层协议非常关心的地方，因为网络层协议比如IP协议会根据这个值来决定是否把上层传下来的数据进行分片，如果单个IP报文长度大于MTU，则会在发送出接口前被分片，被切割为小于或等于MTU长度的IP包。
其实不同厂商对于MTU的定义略有不同，常见的是MTU为IP包的最大长度，如cisco，MTU是指的IP+以太网帧头部，还有的MTU=IP+以太网帧头部+CRC
MTU划分的帧格式 Jumbo帧与MTU 帧过小，导致帧的利用率过小，同时增加分片开销，帧过大，如果丢包导致大量数据重传浪费资源
由于现在场景已由计算密集型转变为IO密集型，大量的网络数据需要进行分片，每个数据包都需要网络设备来进行处理，由此带来的额外开销也将很大，而且这个开销随着网络速度的提高而愈加明显。
于是一些厂商提出了巨型帧（Jumbo Frame）的概念，把以太网的最大帧长扩展到了9K，相当于增强版的MTU，区别在于：
jumbo帧是在数据链路层处理的，MTU涉及的分片通常是在网络层进行的 jumbo帧包括二层以太网帧头和CRC部分，MTU一般不包括这部分，通常是指三层IP报文的长度。 加大帧长的好处在于，减少了网络中数据包的个数，减轻了网络设备处理包头的额外开销。大量减少的帧数目也带来了性能的提高。
TCP MSS和MTU TCP MSS（Maximum Segment Size）是指TCP协议所允许的从对方收到的最大报文长度，即TCP数据包每次能够传输的最大数据分段，只包含TCP Payload，不包含TCP Header和TCP Option。MSS是TCP用来限制application层最大的发送字节数。为了达到最佳的传输效能，TCP协议在建立连接的时候通常要协商双方的MSS值，这个值TCP协议在实现的时候往往根据MTU值来计算（需要减去IP包头20字节和TCP包头20字节），所以通常MSS为1460=1500(MTU)- 20(IP Header) -20 (TCP Header)。
Path MTU 简单来说就是路径上最小的MTU作为这条链路的MTU 路径MTU的探测， UDP和TCP通过ICMP实现，ICMP会回复type为3code为4的差错报文，表示需要分片，但是IP包的DF已设置，导致报文不可达被丢弃，而在icmp回复的报文中会存在下一跳的的MTU值，即PATHMTUDiscovery。
如果主机本地链路的MTU大于端到端链路中某一点的MTU值，那么这个数据包因为有DF=1的原因，会被丢弃。 如果路由器本地链路的MTU为整个端到端链路中最小值时，数据包很幸运的被送达目的地。 对于1，路由器会回复icmp差错报文，同时在差错报文中携带了此路由器的下一跳MTU值。（Destination unreachable(fragmentation needed)），从而调整MTU值。
tcp协议栈会根据路由器回复的icmp报文动态调整mss，实际上处于安全考虑并不是所有的路由器都会回复icmp报文，如果此时没有收到任何icmp报文，tcp会在超时重传后修改mss的值为更小的值。上述的一切基于tcp开启mtu_probing实现
# 默认关闭 [root@giddypoet ~]# cat /proc/sys/net/ipv4/tcp_mtu_probing 0 
          
        </div>

        
          <div>
            <a class="read-more button" href="/posts/mtu/">Read more →</a>
          </div>
        
      </article>
    

    <div class="pagination">
  <div class="pagination__buttons">
    
    
      <a href="/tags/network/page/2/" class="button next">
        <span class="button__text">Older posts</span>
        <span class="button__icon">→</span>
      </a>
    
  </div>
</div>

  </div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>© 2023 Powered by <a href="http://gohugo.io">Hugo</a></span>
    
      <span>:: <a href="https://github.com/panr/hugo-theme-terminal" target="_blank">Theme</a> made by <a href="https://github.com/panr" target="_blank">panr</a></span>
      </div>
  </div>
</footer>






<script type="text/javascript" src="/bundle.min.js"></script>





  
</div>

</body>
</html>
