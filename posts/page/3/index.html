<!DOCTYPE html>
<html lang="en">
<head>
  
    <title>Posts :: GiddyPoet</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="" />
<meta name="keywords" content="" />

  <meta name="robots" content="noodp" />

<link rel="canonical" href="https://giddypoet.github.io/posts/" />






  
  
  
  
  
  <link rel="stylesheet" href="https://giddypoet.github.io/styles.css">







  <link rel="shortcut icon" href="https://giddypoet.github.io/img/theme-colors/blue.png">
  <link rel="apple-touch-icon" href="https://giddypoet.github.io/img/theme-colors/blue.png">



<meta name="twitter:card" content="summary" />

  
    <meta name="twitter:site" content="" />
  
    <meta name="twitter:creator" content="" />



<meta property="og:locale" content="en" />
<meta property="og:type" content="website" />
<meta property="og:title" content="Posts">
<meta property="og:description" content="" />
<meta property="og:url" content="https://giddypoet.github.io/posts/" />
<meta property="og:site_name" content="GiddyPoet" />

  
    <meta property="og:image" content="https://giddypoet.github.io/img/favicon/blue.png">
  

<meta property="og:image:width" content="1200">
<meta property="og:image:height" content="627">





  <link href="/posts/index.xml" rel="alternate" type="application/rss+xml" title="GiddyPoet" />









</head>
<body class="blue">


<div class="container headings--one-size">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="/">
  <div class="logo">
    Terminal
  </div>
</a>

    </div>
    
      <ul class="menu menu--mobile">
  <li class="menu__trigger">Menu&nbsp;▾</li>
  <li>
    <ul class="menu__dropdown">
      
        
          <li><a href="/about">About</a></li>
        
      
        
          <li><a href="/showcase">Showcase</a></li>
        
      
      
    </ul>
  </li>
</ul>

    
    
  </div>
  
    <nav class="navigation-menu">
  <ul class="navigation-menu__inner menu--desktop">
    
      
        
          <li><a href="/about">About</a></li>
        
      
        
          <li><a href="/showcase">Showcase</a></li>
        
      
      
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
  
  <div class="posts">
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="https://giddypoet.github.io/posts/dpdk%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/">dpdk安装部署</a>
        </h1>
        <div class="post-meta">
          
            <time class="post-date">
              2022-02-03 ::
            </time>
          
          
        </div>

        
          <span class="post-tags">
            
            #<a href="https://giddypoet.github.io/tags/network/">network</a>&nbsp;
            
            #<a href="https://giddypoet.github.io/tags/dpdk/">dpdk</a>&nbsp;
            
          </span>
        

        


        <div class="post-content">
          
            基础知识 DPDK在安装时需要对操作系统进行相应的驱动、内存等等做相应的设置，以提升
UMA架构 在一开始，内存控制器还在北桥中，所有CPU对内存的访问都要通过北桥来完成。此时所有CPU访问内存都是“一致的”，如下图所示：
这样的架构称为UMA(Uniform Memory Access)，直译为“统一内存访问”，这样的架构对软件层面来说非常容易，总线模型保证所有的内存访问是一致的，即每个处理器核心共享相同的内存地址空间。但随着CPU核心数的增加，这样的架构难免遇到问题，比如对总线的带宽带来挑战、访问同一块内存的冲突问题。为了解决这些问题，有人搞出了NUMA。
NUMA架构 NUMA 全称 Non-Uniform Memory Access，译为“非一致性内存访问”。这种构架下，不同的内存器件和CPU核心从属不同的 Node，每个 Node 都有自己的集成内存控制器（IMC，Integrated Memory Controller）。
在上述架构中，通常一个内存插槽对应一个Node。需要注意的一个特点是，QPI的延迟要高于IMC Bus，也就是说CPU访问内存有了远近（remote/local）之别，而且实验分析来看，这个差别非常明显。
查看架构 可以通过numactl查看或者通过查看cpu设备信息。
[root@GiddyPoet ~]# numactl --hardware available: 1 nodes (0) node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 node 0 size: 65189 MB node 0 free: 56946 MB node distances: node 0 0: 10 [root@GiddyPoet node]# ls /sys/devices/system/node/ has_cpu has_memory has_normal_memory node0 online possible power uevent 通过上述信息可以查看cpu架构，上述都是uma架构，目前我还没有发现numa架构。
          
        </div>

        
          <div>
            <a class="read-more button" href="/posts/dpdk%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/">Read more →</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="https://giddypoet.github.io/posts/%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/">虚拟网络设备</a>
        </h1>
        <div class="post-meta">
          
            <time class="post-date">
              2022-02-03 ::
            </time>
          
          
        </div>

        
          <span class="post-tags">
            
            #<a href="https://giddypoet.github.io/tags/network/">network</a>&nbsp;
            
          </span>
        

        


        <div class="post-content">
          
            虚拟网络设备 本文将从基础的虚拟网络设备进行介绍，开启linux网络虚拟化的学习之路。
tun/tap tap/tun是linux内核实现的一对虚拟网络设备，TAP工作在二层，tun工作在三层，linux内核通过TAP/TUN设备向绑定该设备的用户空间应用发送数据。反之，用户空间也可以像操作网络硬件设备那样，通过TAP/TUN设备发送数据。
#include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; #include &lt;linux/if_tun.h&gt; #include &lt;linux/if.h&gt; static int create_tun(char *devname,int flags) { int fd; struct ifreq ifr; if((fd = open(&#34;/dev/net/tun&#34;,O_RDWR))&lt;0) { perror(&#34;open&#34;); return ERROR; } memset(&amp;ifr,0,sizeof(ifr)); // IFF_NO_PI，package info，tun/tap会默认在网卡包包信息，信息内容如下 // struct tun_pi { // unsigned short flags; // unsigned short proto; // }; ifr.ifr_flags = flags; strcpy(ifr.ifr_name,devname); if(ioctl(fd,TUNSETIFF,(void*)&amp;ifr)&lt;0) { perror(&#34;ioctl&#34;); return ERROR; } return fd; } Linux Bridge Linux Bridge（网桥）是工作在二层的虚拟网络设备，功能类似于物理的交换机。
对于普通的网络设备来说，只有两端，从一端进来的数据会从另一端出去，如物理网卡从外面物理 网络收到的数据会转发给内核协议栈，而从内核协议栈过来的数据会转发到外面的物理网络中。而 Bridge 不同，Bridge 有多个端口，数据可以从任何端口进来，进来之后从哪个端口出去要看MAC地址， 和物理交换机的原理类似。
          
        </div>

        
          <div>
            <a class="read-more button" href="/posts/%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/">Read more →</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="https://giddypoet.github.io/posts/nic%E6%94%B6%E5%8F%91%E5%8C%85/">nic网卡收包</a>
        </h1>
        <div class="post-meta">
          
            <time class="post-date">
              2022-02-03 ::
            </time>
          
          
        </div>

        
          <span class="post-tags">
            
            #<a href="https://giddypoet.github.io/tags/network/">network</a>&nbsp;
            
          </span>
        

        


        <div class="post-content">
          
            网卡收发包 程序控制I/O 这是最简单的一种 I/O 模式，也叫忙等待或者轮询：用户通过发起一个系统调用，陷入内核态，内核将系统调用翻译成一个对应设备驱动程序的过程调用，接着设备驱动程序会启动 I/O 不断循环去检查该设备，看看是否已经就绪，一般通过返回码来表示，I/O 结束之后，设备驱动程序会把数据送到指定的地方并返回，切回用户态。
cpu一直处于忙轮询状态，调用驱动程序检查设备状态
中断I/O 用户进程发起一个 read() 系统调用读取磁盘文件，陷入内核态并由其所在的 CPU 通过设备驱动程序向设备寄存器写入一个通知信号，告知设备控制器 (我们这里是磁盘控制器)要读取数据； 磁盘控制器启动磁盘读取的过程，把数据从磁盘拷贝到磁盘控制器缓冲区里； 完成拷贝之后磁盘控制器会通过总线发送一个中断信号到中断控制器，如果此时中断控制器手头还有正在处理的中断或者有一个和该中断信号同时到达的更高优先级的中断，则这个中断信号将被忽略，而磁盘控制器会在后面持续发送中断信号直至中断控制器受理； 中断控制器收到磁盘控制器的中断信号之后会通过地址总线存入一个磁盘设备的编号，表示这次中断需要关注的设备是磁盘； 中断控制器向 CPU 置起一个磁盘中断信号； CPU 收到中断信号之后停止当前的工作，把当前的 PC/PSW 等寄存器压入堆栈保存现场，然后从地址总线取出设备编号，通过编号找到中断向量所包含的中断服务的入口地址，压入 PC 寄存器，开始运行磁盘中断服务，把数据从磁盘控制器的缓冲区拷贝到主存里的内核缓冲区； 最后 CPU 再把数据从内核缓冲区拷贝到用户缓冲区，完成读取操作，read() 返回，切换回用户态。 内核调用硬盘驱动，实现将数据从硬盘拷贝至硬盘控制器缓冲区，然后传递设备号，触发中断（硬中断），之后cpu将数据从硬盘控制器缓存区拷贝出来传递到内存中，再拷贝到用户缓存区。
DMA I/O 在上述中断I/O中，当网卡控制器将数据从硬盘上存储到自身的缓存区后，cpu负责将数据从网卡控制器的缓存区搬运至内存中再拷贝至用户态，在这两次数据拷贝阶段中CPU是完全被占用而不能处理其他工作的。由于从内核态拷贝到用户态都在主存中，只能由cpu完成，但是第 6 步的数据拷贝，是从磁盘控制器的缓冲区到主存，是两个设备之间的数据传输，这一步并非一定要 CPU 来完成，可以借助 DMA 来完成，减轻 CPU 的负担。
DMA 全称是 Direct Memory Access，也即直接存储器存取，是一种用来提供在外设和存储器之间或者存储器和存储器之间的高速数据传输。整个过程无须 CPU 参与，数据直接通过 DMA 控制器进行快速地移动拷贝，节省 CPU 的资源去做其他工作。
用户进程发起一个 read() 系统调用读取磁盘文件，陷入内核态并由其所在的 CPU 通过设置 DMA 控制器的寄存器对它进行编程：把内核缓冲区和磁盘文件的地址分别写入 MAR 和 ADR 寄存器，然后把期望读取的字节数写入 WC 寄存器，启动 DMA 控制器； DMA 控制器根据 ADR 寄存器里的信息知道这次 I/O 需要读取的外设是磁盘的某个地址，便向磁盘控制器发出一个命令，通知它从磁盘读取数据到其内部的缓冲区里； 磁盘控制器启动磁盘读取的过程，把数据从磁盘拷贝到磁盘控制器缓冲区里，并对缓冲区内数据的校验和进行检验，如果数据是有效的，那么 DMA 就可以开始了； DMA 控制器通过总线向磁盘控制器发出一个读请求信号从而发起 DMA 传输，这个信号和前面的中断驱动 I/O 小节里 CPU 发给磁盘控制器的读请求是一样的，它并不知道或者并不关心这个读请求是来自 CPU 还是 DMA 控制器； 紧接着 DMA 控制器将引导磁盘控制器将数据传输到 MAR 寄存器里的地址，也就是内核缓冲区； 数据传输完成之后，返回一个 ack 给 DMA 控制器，WC 寄存器里的值会减去相应的数据长度，如果 WC 还不为 0，则重复第 4 步到第 6 步，一直到 WC 里的字节数等于 0； 收到 ack 信号的 DMA 控制器会通过总线发送一个中断信号到中断控制器，如果此时中断控制器手头还有正在处理的中断或者有一个和该中断信号同时到达的更高优先级的中断，则这个中断信号将被忽略，而 DMA 控制器会在后面持续发送中断信号直至中断控制器受理； 中断控制器收到磁盘控制器的中断信号之后会通过地址总线存入一个主存设备的编号，表示这次中断需要关注的设备是主存； 中断控制器向 CPU 置起一个 DMA 中断的信号； CPU 收到中断信号之后停止当前的工作，把当前的 PC/PSW 等寄存器压入堆栈保存现场，然后从地址总线取出设备编号，通过编号找到中断向量所包含的中断服务的入口地址，压入 PC 寄存器，开始运行 DMA 中断服务，把数据从内核缓冲区拷贝到用户缓冲区，完成读取操作，read() 返回，切换回用户态。 简单来说就是通过DMA将数据从硬盘控制器缓存区拷贝到内存中，减少了一次CPU COPY。
          
        </div>

        
          <div>
            <a class="read-more button" href="/posts/nic%E6%94%B6%E5%8F%91%E5%8C%85/">Read more →</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="https://giddypoet.github.io/posts/mtu/"></a>
        </h1>
        <div class="post-meta">
          
          
        </div>

        

        


        <div class="post-content">
          
             title: mtu date: 2022-03-25 09:52:24 tags: [network] categories: [os] MTU Maximum Transmission Unit 最大传输单元。
不同链路介质对网络有不同的默认MTU值，以下是一些常见的默认值:
以太网MTU通常被设置为1500。
为什么以太网帧mtu被设为1500 早期的以太网使用共享链路的工作方式，为了保证CSMA/CD（载波多路复用/冲突检测）机制，所以规定了以太帧长度最小为64字节，最大为1518字节。最小64字节是为了保证最极端的冲突能被检测到，64字节是能被检测到的最小值；最大不超过1518字节是为了防止过长的帧传输时间过长而占用共享链路太长时间导致其他业务阻塞。所以规定以太网帧大小为64~1518字节，虽然技术不断发展，但协议一直没有更改。
以太网最大的数据帧是1518字节，这样刨去帧头14字节和帧尾CRC校验部分4字节，那么剩下承载上层IP报文的地方最大就只有1500字节，这个值就是以太网的默认MTU值。这个MTU就是网络层协议非常关心的地方，因为网络层协议比如IP协议会根据这个值来决定是否把上层传下来的数据进行分片，如果单个IP报文长度大于MTU，则会在发送出接口前被分片，被切割为小于或等于MTU长度的IP包。
其实不同厂商对于MTU的定义略有不同，常见的是MTU为IP包的最大长度，如cisco，MTU是指的IP+以太网帧头部，还有的MTU=IP+以太网帧头部+CRC
MTU划分的帧格式 Jumbo帧与MTU 帧过小，导致帧的利用率过小，同时增加分片开销，帧过大，如果丢包导致大量数据重传浪费资源
由于现在场景已由计算密集型转变为IO密集型，大量的网络数据需要进行分片，每个数据包都需要网络设备来进行处理，由此带来的额外开销也将很大，而且这个开销随着网络速度的提高而愈加明显。
于是一些厂商提出了巨型帧（Jumbo Frame）的概念，把以太网的最大帧长扩展到了9K，相当于增强版的MTU，区别在于：
jumbo帧是在数据链路层处理的，MTU涉及的分片通常是在网络层进行的 jumbo帧包括二层以太网帧头和CRC部分，MTU一般不包括这部分，通常是指三层IP报文的长度。 加大帧长的好处在于，减少了网络中数据包的个数，减轻了网络设备处理包头的额外开销。大量减少的帧数目也带来了性能的提高。
TCP MSS和MTU TCP MSS（Maximum Segment Size）是指TCP协议所允许的从对方收到的最大报文长度，即TCP数据包每次能够传输的最大数据分段，只包含TCP Payload，不包含TCP Header和TCP Option。MSS是TCP用来限制application层最大的发送字节数。为了达到最佳的传输效能，TCP协议在建立连接的时候通常要协商双方的MSS值，这个值TCP协议在实现的时候往往根据MTU值来计算（需要减去IP包头20字节和TCP包头20字节），所以通常MSS为1460=1500(MTU)- 20(IP Header) -20 (TCP Header)。
Path MTU 简单来说就是路径上最小的MTU作为这条链路的MTU 路径MTU的探测， UDP和TCP通过ICMP实现，ICMP会回复type为3code为4的差错报文，表示需要分片，但是IP包的DF已设置，导致报文不可达被丢弃，而在icmp回复的报文中会存在下一跳的的MTU值，即PATHMTUDiscovery。
如果主机本地链路的MTU大于端到端链路中某一点的MTU值，那么这个数据包因为有DF=1的原因，会被丢弃。 如果路由器本地链路的MTU为整个端到端链路中最小值时，数据包很幸运的被送达目的地。 对于1，路由器会回复icmp差错报文，同时在差错报文中携带了此路由器的下一跳MTU值。（Destination unreachable(fragmentation needed)），从而调整MTU值。
tcp协议栈会根据路由器回复的icmp报文动态调整mss，实际上处于安全考虑并不是所有的路由器都会回复icmp报文，如果此时没有收到任何icmp报文，tcp会在超时重传后修改mss的值为更小的值。上述的一切基于tcp开启mtu_probing实现
# 默认关闭 [root@giddypoet ~]# cat /proc/sys/net/ipv4/tcp_mtu_probing 0 
          
        </div>

        
          <div>
            <a class="read-more button" href="/posts/mtu/">Read more →</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="https://giddypoet.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%98%AF%E6%80%8E%E6%A0%B7%E8%B7%91%E8%B5%B7%E6%9D%A5%E7%9A%84/"></a>
        </h1>
        <div class="post-meta">
          
          
        </div>

        

        


        <div class="post-content">
          
            title: 计算机是怎样跑起来的 date: 2022-04-12 20:20:48 tags: [computer] categories: [computer] &laquo;计算机是怎么跑起来的&raquo; 读书笔记
计算机三大原则 计算机的三个根本性基础 计算机是执行输入、运算、输出的机器 程序是指令和数据的集合 计算机的处理方式与人们的思维习惯不同 输入、运算、输出是硬件的基础 计算机是执行输入、运算、输出三种操作的机器。IC电路引脚也是围绕这个点进行设计的。
软件是指令和数据的集合 objdump xxx 对计算机来说什么都是数字 这一章围绕作者提出的计算机的三个根本性基础，举例阐述佐证了作者的观点。
试着制造一台计算机吧 制作微型计算机所必需的元件 基础元件：
cpu：解释、执行程序（文中采用的是Z80 CPU） 内存：存储程序和数据（文中采用的是TC5517） I/O：连接外部设备（文中采用的是Z80 PIO） 为了驱动CPU运转，时钟信号必不可少，通过高低电平切换，驱动CPU操作。简单来说时钟信号用于同步操作。
下述其实是D触发器，当CLK为高电平的时候，当clk是1的时候，D的值就会被写进去，然后clk=0的时候，Q就会一直是之前那个D，clk是0的时候，D的值再变，Q也不会变。为什么需要clk呢，因为你的设计里面，这个寄存器在等上一个寄存器的数据，你不知道上一个寄存器的数据存好了没，是新的还是旧的，你要写进去的数据写好了没。如果每个寄存器都用不同的clk，这样设计很容易不同步async，就是我想同时写几个register，但是这个register已经写完了，那个我不知道他存好了没，全局的clk能帮助解决很多这类问题。这个clk很大程度上左右了设计里面很多东西的读写速度。
当然，实际上的设计一般clk还会AND 一个叫enable的输入，那么当enable是0的时候，clk那边就一直是0，你要写进去这个flipflop，就需要enable=1，clk=1，这时候D就被存进去了。
输入程序的装置也是必不可少的，通过拨动指拨开关来输入程序，8个开关作为输入元件，输出元件是8个LED。
同时还有DMA，将输入输出直接写入内存当中。
此章节主要介绍了计算机的组成，设计到一些嵌入式单片机的知识，未做详细的描述，将其略过。
体验一次手工汇编 实际上通过上述计算机输入的二进制序列，实现汇编指令，驱动CPU实现指令。
这里不再赘述
程序像河水一样流动着 程序的流程分为三种 计算机的硬件系统由CPU、I/O和内存三部分构成。内存中存储这程序，也就是指令和数据。CPU配合着时钟发生器的时钟信号，从内存中读出指令，然后再依次对其进行解释和执行。
CPU中有各种各样的各司其职的寄存器。其中有一个被称为PC（Program Counter，程序计数器）的寄存器，负责存储内存地址，该地址指向下一条即将执行的指令，每解释执行完一条指令，PC寄存器的值就会自动被更新为下一条指令的地址。
实际上程序的流程总共有三种，由PC控制器控制：
顺序执行 条件分支 循环 特殊的程序流程&ndash;中断处理 处理中断
该书后续的介绍都较为浅显，偏入门的知识介绍，暂时不在阅读
          
        </div>

        
          <div>
            <a class="read-more button" href="/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%98%AF%E6%80%8E%E6%A0%B7%E8%B7%91%E8%B5%B7%E6%9D%A5%E7%9A%84/">Read more →</a>
          </div>
        
      </article>
    

    <div class="pagination">
  <div class="pagination__buttons">
    
      <a href="/posts/page/2/" class="button previous">
        <span class="button__icon">←</span>
        <span class="button__text">Newer posts</span>
      </a>
    
    
  </div>
</div>

  </div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>© 2023 Powered by <a href="http://gohugo.io">Hugo</a></span>
    
      <span>:: <a href="https://github.com/panr/hugo-theme-terminal" target="_blank">Theme</a> made by <a href="https://github.com/panr" target="_blank">panr</a></span>
      </div>
  </div>
</footer>






<script type="text/javascript" src="/bundle.min.js"></script>





  
</div>

</body>
</html>
